import os
import random
import shutil

import numpy as np
import torch
from torchvision.transforms import transforms
from torch.backends import cudnn
from torch.utils.data import ConcatDataset
from lib.continual import datafree
from lib.dataset import TransformedDataset, AVAILABLE_TRANSFORMS


class MI_DFCL_handler:
    """Our approach DDC"""

    def __init__(self, dataset_handler, cfg, logger):
        self.dataset_handler = dataset_handler  # Torchvision_Datasets_Splitè´Ÿè´£å§æ•°æ®é›†åˆ’åˆ†æˆå¤šä¸ªä»»åŠ¡
        self.cfg = cfg
        self.logger = logger
        self.trainer_name = self.cfg.trainer_name  #è¿™é‡Œä¼šå®ä¾‹åŒ–ä½ é€‰æ‹©çš„â€œç®—æ³•å®ç°ç±»â€ï¼Œæ¯”å¦‚ FARLSTM_Trainer æˆ– FARLSTM_EFCL_Trainerï¼ˆå…·ä½“ç±»åçœ‹å·¥ç¨‹ï¼‰ã€‚
        self.trainer = None

        self.start_task_id = None

        self.handler_init()

    def handler_init(self):
        """
        å‡è®¾è®ºæ–‡æ¯ä¸€é˜¶æ®µéƒ½æœ‰ä¸€ä¸ªæ—§æ¨¡å‹f_t-1,å’Œå½“å‰é˜¶æ®µæ•°æ®D_t,
        RESUMEåˆ†æ”¯ï¼š1ã€ä»checkpointæ¢å¤ä¹‹å‰çš„f_t-1ã€å†å²ä»»åŠ¡åˆ’åˆ†(split_selected_data)ã€‚2ã€ä»ä¸­é—´taskç»§ç»­Stage1+Stage2çš„è®­ç»ƒ
        :return:
        """
        if self.cfg.RESUME.use_resume:
            self.logger.info(f"use_resume: {self.cfg.RESUME.resumed_model_path}")
            checkpoint = torch.load(self.cfg.RESUME.resumed_model_path)
            self.start_task_id = checkpoint['task_id']
            self.dataset_handler.update_split_selected_data(checkpoint["split_selected_data"])
            self.dataset_handler.get_dataset()
            self.trainer = datafree.__dict__[self.trainer_name](self.cfg, self.dataset_handler, self.logger)
            self.trainer.resume(self.cfg.RESUME.resumed_model_path, checkpoint)
            self.trainer.print_model()
        else:
            #get_dataset()ï¼š1ã€åˆ’åˆ†æ•°æ®é›†ï¼›2ã€åˆå§‹åŒ–æ•°æ®å¢å¼ºå™¨ï¼›3ã€åˆå§‹åŒ–æ•°æ®é›†ï¼›4ã€åˆå§‹åŒ–æ¨¡å‹ï¼›5ã€åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼›6ã€åˆå§‹åŒ–å­¦ä¹ ç‡è¡°å‡å™¨ï¼›7ã€åˆå§‹åŒ–è¯„ä»·æŒ‡æ ‡ï¼›8ã€åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨ï¼›9ã€åˆå§‹åŒ–è®­ç»ƒå™¨ã€‚
            self.dataset_handler.get_dataset()
            self.trainer = datafree.__dict__[self.trainer_name](self.cfg, self.dataset_handler, self.logger)
            self.trainer.print_model()

    def midfcl_train_main(self):
        gpus = torch.cuda.device_count()
        self.logger.info(f"use {gpus} gpus")
        random.seed(self.cfg.seed)
        np.random.seed(self.cfg.seed)
        torch.manual_seed(self.cfg.seed)
        torch.cuda.manual_seed(self.cfg.seed)
        # determinstic backend
        torch.backends.cudnn.deterministic = True

        '''mkdir direction for storing codes and checkpoint'''
        model_dir = os.path.join(self.cfg.OUTPUT_DIR, "models")
        code_dir = os.path.join(self.cfg.OUTPUT_DIR, "codes")

        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
        else:
            self.logger.info(
                "This directory has already existed, Please remember to modify your cfg.NAME"
            )
            print("os.path.exists(code_dir):", os.path.exists(code_dir))
            if os.path.exists(code_dir):
                shutil.rmtree(code_dir)
            assert not os.path.exists(code_dir)
        self.logger.info("=> output model will be saved in {}".format(model_dir))
        this_dir = os.path.dirname(__file__)
        ignore = shutil.ignore_patterns(
            "*.pyc", "*.so", "*.out", "*pycache*", "*.pth", "*build*", "*output*", "*datasets*"
        )
        shutil.copytree(os.path.join(this_dir, "../"), code_dir, ignore=ignore)

        '''Construct dataset for each task.
        æ•°æ®å¢å¼ºï¼šå¯¹åº”è®ºæ–‡ IV.A ä¸­çš„æ•°æ®é¢„å¤„ç†ï¼Œå¯¹åº”è®ºæ–‡ Experiment Setup é‡Œå…³äºæ•°æ®å¢å¼ºçš„æè¿°ï¼ˆpadding + random crop + horizontal flip ç­‰
        '''
        if self.cfg.use_Contra_train_transform:
            train_dataset_transform = transforms.Compose([
                *AVAILABLE_TRANSFORMS[self.dataset_handler.dataset_name]['Contra_train_transform'],
            ])
        else:
            train_dataset_transform = transforms.Compose([
                *AVAILABLE_TRANSFORMS[self.dataset_handler.dataset_name]['train_transform'],
            ])
        """
        self.dataset_handler.dataset_nameæ¯”å¦‚æ˜¯ 'CIFAR100' / 'mnist'ï¼Œæ¥è‡ªä½ å‰é¢çš„ Torchvision_Datasets_Split
            self.dataset_name = cfg.DATASET.dataset_name  # CIFAR100 / CIFAR10 / mnistâ€¦
            
        AVAILABLE_TRANSFORMS['CIFAR100'] = {
            "Contra_train_transform": [...],
            "train_transform": [...],
            "test_transform": [...],
        }

        
        """

        """
        ä»»åŠ¡å¾ªç¯ï¼šå¯¹åº”è®ºæ–‡çš„ã€ŒBase-0 / Base-Half åè®® + æ¯ä¸€é˜¶æ®µè®­ç»ƒã€
        ç¡®å®šä»å“ªä¸€ä¸ªtaskå¼€å§‹è®­ç»ƒï¼Œä»å“ªä¸€ä¸ªtaskå¼€å§‹æµ‹è¯•ï¼Œä»¥åŠæ¯ä¸€é˜¶æ®µè®­ç»ƒçš„taskæ•°é‡ã€‚
        """
        if not self.cfg.RESUME.use_resume:
            self.start_task_id = 1  # å¦‚æœæ²¡ resumeï¼Œå°±ä» task=1 å¼€å§‹ï¼ˆå¯¹åº”è®ºæ–‡ç¬¬ä¸€é˜¶æ®µt=1ï¼‰
        else:
            self.start_task_id += 1 # å¦‚æœæ˜¯ resumeï¼Œåˆ™ä» checkpoint é‡Œçš„ task_id+1 å¼€å§‹ç»§ç»­è®­ç»ƒ

        #æŒ‰é˜¶æ®µéå†æ•°æ®é›†ï¼Œæ¯ä¸€é˜¶æ®µè®­ç»ƒä¸€ä¸ªtask
        train_dataset = None
        for task, original_imgs_train_dataset in enumerate(self.dataset_handler.original_imgs_train_datasets, #å°±æ˜¯å½“å‰é˜¶æ®µçš„çœŸå®è®­ç»ƒæ•°æ®ï¼ˆè¿˜æ²¡åŠ  transform çš„ï¼‰
                                                           1):
            self.logger.info(f'New task {task} begin.')

            if self.cfg.RESUME.use_resume and task < self.start_task_id:
                self.logger.info(f"Use resume. continue.")
                continue

                """
                Base-0 (cold-start)ï¼šæ‰€æœ‰ç±»åˆ«å¹³å‡åˆ‡æˆ 5/10/20 ä¸ªé˜¶æ®µï¼Œç¬¬ 1 é˜¶æ®µåªçœ‹ç¬¬ä¸€æ‰¹ç±»ã€‚

                Base-Half (warm-start)ï¼šå‰ä¸€åŠç±»åˆ«ä½œä¸º base taskï¼Œåé¢æ‹†æˆ 5 ä¸ªé˜¶æ®µã€‚
                """
            if self.cfg.use_base_half and task < int(self.dataset_handler.all_tasks / 2):
                train_dataset_temp = TransformedDataset(original_imgs_train_dataset, transform=train_dataset_transform)

                if train_dataset is None:
                    train_dataset = train_dataset_temp
                else:
                    train_dataset = ConcatDataset([train_dataset, train_dataset_temp])
                self.logger.info(f'task continue.')
                continue
            else:
                if self.cfg.use_base_half:
                    if task == int(self.dataset_handler.all_tasks / 2):
                        train_dataset_temp = TransformedDataset(original_imgs_train_dataset,
                                                                transform=train_dataset_transform)

                        train_dataset = ConcatDataset([train_dataset, train_dataset_temp])
                        self.logger.info(f'base_half dataset construct end.')
                        # self.batch_train_logger.info(f'base_half dataset construct end.')
                        self.logger.info(f'train_dataset length: {len(train_dataset)}.')
                    elif task > int(self.dataset_handler.all_tasks / 2):
                        train_dataset = TransformedDataset(original_imgs_train_dataset,
                                                           transform=train_dataset_transform)
                    else:
                        train_dataset = None
                else:
                    train_dataset = TransformedDataset(original_imgs_train_dataset, transform=train_dataset_transform)




            '''Train models to learn tasks
            çœŸæ­£è®­ç»ƒçš„å…¥å£ï¼šå’Œè®ºæ–‡ Stage1 / Stage2 çš„è¿æ¥ç‚¹
            åˆ°äº†è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»æ‹¿åˆ°äº†å½“å‰é˜¶æ®µè¦ç”¨çš„ train_datasetï¼Œä¸‹ä¸€æ­¥æ˜¯â€œè®©æ¨¡å‹å­¦è¿™æ‰¹ä»»åŠ¡â€ã€‚
            å¯¹åº”è®ºæ–‡çš„ Stage1 / Stage2 è®­ç»ƒï¼Œæˆ‘ä»¬ä¼šè°ƒç”¨ trainer é‡Œçš„ learn_new_task() æ–¹æ³•ï¼Œå…·ä½“å®ç°çœ‹å…·ä½“çš„ trainer ç±»ã€‚
            '''
            active_classes_num = self.dataset_handler.classes_per_task * task
            """active_classes_num= æ¯ä¸ªä»»åŠ¡çš„ç±»åˆ«æ•° Ã— å½“å‰ä»»åŠ¡ç¼–å·å¯¹åº”è®ºæ–‡é‡Œçš„ â€œå­¦åˆ°ç¬¬ t é˜¶æ®µæ—¶ï¼Œæ¨¡å‹è¦èƒ½åˆ†è¾¨å‰ t ä¸ªé˜¶æ®µçš„æ‰€æœ‰ç±»â€ã€‚
            """
            if self.cfg.use_base_half and task == int(self.dataset_handler.all_tasks / 2) or \
                    (not self.cfg.use_base_half and task == 1):
                """
                Base-Halfï¼štask == all_tasks/2ï¼ˆå³â€œbase ä»»åŠ¡â€æ”¶å°¾é˜¶æ®µï¼‰ï¼Œæˆ–è€…Base-0ï¼štask == 1ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰ï¼Œ åˆ™è°ƒç”¨ first_task_train_mainã€‚
                """
                if self.cfg.train_first_task:
                    self.trainer.first_task_train_main(train_dataset, active_classes_num, task)#åœ¨ç¬¬ä¸€é˜¶æ®µï¼ˆæˆ– base ä»»åŠ¡ï¼‰è¿˜ä¸å­˜åœ¨æ—§æ¨¡å‹å¯ä»¥ distillï¼Œæ‰€ä»¥åªéœ€è¦ä¼ ç»Ÿçš„ CE è®­ç»ƒï¼ˆæ²¡æœ‰ Stage1/Stage2 çš„å¤æ‚ KDï¼‰
                    #æ ‡å‡† supervised trainingï¼Œloss â‰ˆ CEï¼ˆå¯èƒ½å¸¦ä¸€ç‚¹ regularizationï¼‰ã€‚è®­ç»ƒå‡ºåˆå§‹çš„ ğ‘“_1ï¼Œæˆ–baseæ¨¡å‹

                else:
                    self.trainer.load_model(self.cfg.task1_MODEL)
            else:
                self.trainer.learn_new_task(train_dataset, active_classes_num, task)
            if "DualConsistencyMI" == self.cfg.trainer_name:
                self.trainer.after_steps(train_dataset, task)
            self.logger.info(f'#############MCFM train task {task} End.##############')
            self.logger.info(f'#############Example handler task {task} start.##############')

            '''Evaluation.'''
            val_acc = self.trainer.validate_with_FC(task=task)
            if "DualConsistencyMI" == self.cfg.trainer_name:
                val_acc_Routing = self.trainer.validate_with_FC_Prototypical_Routing(task=task)
            taskIL_FC_val_acc = self.trainer.validate_with_FC_taskIL(task=task)
            test_acc = None
            self.logger.info(f'#############task: {task:0>3d} is finished Test begin. ##############')
            if self.dataset_handler.val_datasets:
                test_acc = self.trainer.validate_with_FC(task=task, is_test=True)
                taskIL_FC_test_acc = self.trainer.validate_with_FC_taskIL(task, is_test=True)

                val_acc_FC_str = f'task: {task} classififer:{"FC"} val_acc: {val_acc}, avg: {val_acc.mean()} '
                test_acc_FC_str = f'task: {task} classififer:{"FC"} || test_acc: {test_acc}, avg: {test_acc.mean()} '
                self.logger.info(val_acc_FC_str)
                self.logger.info(test_acc_FC_str)
                self.logger.info(f"validate taskIL: val FC: {taskIL_FC_val_acc} || {taskIL_FC_val_acc.mean()}")
                self.logger.info(f"validate taskIL: test FC: {taskIL_FC_test_acc} || {taskIL_FC_test_acc.mean()}")
            else:
                test_acc_FC_str = f'task: {task} classififer:{"FC"} || test_acc: {val_acc}, avg: {val_acc.mean()} '
                self.logger.info(test_acc_FC_str)
                if "DualConsistencyMI" == self.cfg.trainer_name:
                    test_acc_FC_str_Routing = f'task: {task} classififer:{"FC_Routing"} || test_acc: {val_acc_Routing}, ' \
                                      f'avg: {val_acc_Routing.mean()} '
                    self.logger.info(test_acc_FC_str_Routing)

                self.logger.info(f"validate taskIL: FC: {taskIL_FC_val_acc} || {taskIL_FC_val_acc.mean()}")

            if test_acc:
                if self.cfg.save_model:
                    self.trainer.save_best_latest_model_data(model_dir, task, test_acc.mean(),
                                                             self.cfg.model.TRAIN.MAX_EPOCH)
            else:
                if self.cfg.save_model:
                    self.trainer.save_best_latest_model_data(model_dir, task, val_acc.mean(),
                                                             self.cfg.model.TRAIN.MAX_EPOCH)


    def midfcl_train_main_for_local_dataset(self):
        gpus = torch.cuda.device_count()
        self.logger.info(f"use {gpus} gpus")
        random.seed(self.cfg.seed)
        np.random.seed(self.cfg.seed)
        torch.manual_seed(self.cfg.seed)
        torch.cuda.manual_seed(self.cfg.seed)
        # determinstic backend
        torch.backends.cudnn.deterministic = True

        '''mkdir direction for storing codes and checkpoint'''
        model_dir = os.path.join(self.cfg.OUTPUT_DIR, "models")
        code_dir = os.path.join(self.cfg.OUTPUT_DIR, "codes")

        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
        else:
            self.logger.info(
                "This directory has already existed, Please remember to modify your cfg.NAME"
            )
            print("os.path.exists(code_dir):", os.path.exists(code_dir))
            if os.path.exists(code_dir):
                shutil.rmtree(code_dir)
            assert not os.path.exists(code_dir)
        self.logger.info("=> output model will be saved in {}".format(model_dir))
        this_dir = os.path.dirname(__file__)
        ignore = shutil.ignore_patterns(
            "*.pyc", "*.so", "*.out", "*pycache*", "*.pth", "*build*", "*output*", "*datasets*"
        )
        shutil.copytree(os.path.join(this_dir, "../"), code_dir, ignore=ignore)

        '''Construct dataset for each task.'''
        if self.cfg.use_Contra_train_transform:
            train_dataset_transform = transforms.Compose([
                *AVAILABLE_TRANSFORMS[self.dataset_handler.dataset_name]['Contra_train_transform'],
            ])
        else:
            train_dataset_transform = transforms.Compose([
                *AVAILABLE_TRANSFORMS[self.dataset_handler.dataset_name]['train_transform'],
            ])

        if not self.cfg.RESUME.use_resume:
            self.start_task_id = 1  # self.start_task_id ä» 1 å¼€å§‹
        else:
            self.start_task_id += 1
        train_dataset = None
        for task, original_imgs_train_dataset in enumerate(self.dataset_handler.original_imgs_train_datasets,
                                                           1):
            self.logger.info(f'New task {task} begin.')

            if self.cfg.RESUME.use_resume and task < self.start_task_id:
                self.logger.info(f"Use resume. continue.")
                continue

            if self.cfg.use_base_half and task < int(self.dataset_handler.all_tasks / 2):
                train_dataset_temp = TransformedDataset(original_imgs_train_dataset, transform=train_dataset_transform)

                if train_dataset is None:
                    train_dataset = train_dataset_temp
                else:
                    train_dataset = ConcatDataset([train_dataset, train_dataset_temp])
                self.logger.info(f'task continue.')
                continue
            else:
                if self.cfg.use_base_half:
                    if task == int(self.dataset_handler.all_tasks / 2):
                        train_dataset_temp = TransformedDataset(original_imgs_train_dataset,
                                                                transform=train_dataset_transform)

                        train_dataset = ConcatDataset([train_dataset, train_dataset_temp])
                        self.logger.info(f'base_half dataset construct end.')
                        # self.batch_train_logger.info(f'base_half dataset construct end.')
                        self.logger.info(f'train_dataset length: {len(train_dataset)}.')
                    elif task > int(self.dataset_handler.all_tasks / 2):
                        train_dataset = TransformedDataset(original_imgs_train_dataset,
                                                           transform=train_dataset_transform)
                    else:
                        train_dataset = None
                else:
                    train_dataset = TransformedDataset(original_imgs_train_dataset, transform=train_dataset_transform)

            '''Train models to learn tasks'''
            active_classes_num = self.dataset_handler.classes_per_task * task
            if self.cfg.use_base_half and task == int(self.dataset_handler.all_tasks / 2) or \
                    (not self.cfg.use_base_half and task == 1):
                if self.cfg.train_first_task:
                    self.trainer.first_task_train_main(train_dataset, active_classes_num, task)
                else:
                    self.trainer.load_model(self.cfg.task1_MODEL)
            else:
                self.trainer.learn_new_task(train_dataset, active_classes_num, task)
            self.logger.info(f'#############MCFM train task {task} End.##############')
            self.logger.info(f'#############Example handler task {task} start.##############')

            '''Evaluation.'''
            val_acc = self.trainer.validate_with_FC(task)
            taskIL_FC_val_acc = self.trainer.validate_with_FC_taskIL(task)
            test_acc = None
            self.logger.info(f'#############task: {task:0>3d} is finished Test begin. ##############')
            if self.dataset_handler.val_datasets:
                test_acc = self.trainer.validate_with_FC(task=task, is_test=True)
                taskIL_FC_test_acc = self.trainer.validate_with_FC_taskIL(task, is_test=True)

                val_acc_FC_str = f'task: {task} classififer:{"FC"} val_acc: {val_acc}, avg: {val_acc.mean()} '
                test_acc_FC_str = f'task: {task} classififer:{"FC"} || test_acc: {test_acc}, avg: {test_acc.mean()} '
                self.logger.info(val_acc_FC_str)
                self.logger.info(test_acc_FC_str)
                self.logger.info(f"validate taskIL: val FC: {taskIL_FC_val_acc} || {taskIL_FC_val_acc.mean()}")
                self.logger.info(f"validate taskIL: test FC: {taskIL_FC_test_acc} || {taskIL_FC_test_acc.mean()}")
            else:
                test_acc_FC_str = f'task: {task} classififer:{"FC"} || test_acc: {val_acc}, avg: {val_acc.mean()} '
                self.logger.info(test_acc_FC_str)
                self.logger.info(f"validate taskIL: FC: {taskIL_FC_val_acc} || {taskIL_FC_val_acc.mean()}")

            if test_acc:
                if self.cfg.save_model:
                    self.trainer.save_best_latest_model_data(model_dir, task, test_acc.mean(),
                                                             self.cfg.model.TRAIN.MAX_EPOCH)
            else:
                if self.cfg.save_model:
                    self.trainer.save_best_latest_model_data(model_dir, task, val_acc.mean(),
                                                             self.cfg.model.TRAIN.MAX_EPOCH)
